{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages and start Matlab engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy import io as spio\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "rnd.seed(seed)\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "\n",
    "import h5py\n",
    "import matlab\n",
    "import matlab.engine\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, STATUS_FAIL, Trials\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt.fmin import generate_trials_to_calculate\n",
    "from functools import reduce\n",
    "\n",
    "from s2synth import rr_s2_data, mod_6_crop_s2_data\n",
    "from sreval import rmse, sre, uiqi, ergas, sam, ssim\n",
    "from sreval import sreval, evaluate_performance, dataframe_from_res_list\n",
    "\n",
    "from mat_loaders import get_data\n",
    "\n",
    "from S2_SSC_CNN.SSCwrap import SSCwrap\n",
    "\n",
    "from boars import opt_method, data_list, meth_list, best_pars, get_method, pardict_to_matlist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot styles and size\n",
    "%matplotlib inline\n",
    "sns.set_style(\"ticks\", rc={\"axes.grid\":True})\n",
    "sns.set_context(\"paper\", font_scale=2.5)\n",
    "cmap = sns.color_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_evals = 150\n",
    "metric = 'sre'\n",
    "verbose = False\n",
    "eval_bands=[2,6]\n",
    "result_dir = './results/' + time.strftime(\"%Y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_list:\n",
    "    if dataset not in best_pars.keys(): best_pars[dataset] = {}\n",
    "    # Make directory to save resullts\n",
    "    os.makedirs(result_dir + '/' + dataset, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best parameters for S2 SSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 2 in eval_bands:\n",
    "    method = SSCwrap\n",
    "    SSCparameters = {'batch_size': ['int', 64, ('uniform_int', 16, 64)],\n",
    "                     'lr': ['double', 0.0005, ('lognormal', np.exp(0.1), 0.5)],\n",
    "                     'mtf_down': ['bool', True, ('choice', True, False)],\n",
    "                     'ndown': ['int', 3, ('constant')],\n",
    "                     'num_epochs': ['int', 200, ('constant')],\n",
    "                     'verbose': ['string', False, ('constant')]}\n",
    "\n",
    "    for dataset in data_list:\n",
    "        try:\n",
    "            print('Tuning S2 SSC parameters for', dataset)\n",
    "            SSCpars = opt_method(method, SSCparameters, max_evals, dataset=dataset, metric=metric, eval_bands=[2], verbose=True, matlab_func=False, savefile=result_dir + '/' + dataset + '/' + 'SSC')\n",
    "            best_pars[dataset]['SSC'] = SSCpars\n",
    "        except:\n",
    "            print('Parameter tuning for S2 SSC failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best parameters for S2Sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.addpath('./S2Sharp')\n",
    "S2sharpwrap = eng.S2sharpwrap\n",
    "method = S2sharpwrap\n",
    "S2sharpparameters = {'r': ['int', 8, ('uniform_int', 5, 9)], \n",
    "              'q1': ['double', 1, ('lognormal', 0, 0.5)], \n",
    "              'q2': ['double', 0.3851, ('lognormal', 0, 0.5)], \n",
    "              'q3': ['double', 6.9039, ('lognormal', 0, 0.5)], \n",
    "              'q4': ['double', 19.9581, ('lognormal', 0, 0.5)], \n",
    "              'q5': ['double', 47.8967, ('lognormal', 0, 0.5)], \n",
    "              'q6': ['double', 27.5518, ('lognormal', 0, 0.5)], \n",
    "              'q7': ['double', 2.7100, ('lognormal', 0, 0.5)], \n",
    "              'q8': ['double', 34.8689, ('lognormal', 0, 0.5)], \n",
    "              'q9': ['double', 1, ('lognormal', 0, 0.5)], \n",
    "              'q10': ['double', 1, ('lognormal', 0, 0.5)], \n",
    "              'lam': ['double', 1.8998e-04, ('lognormal', np.exp(0.005), 0.5)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_list:\n",
    "    try:\n",
    "        print('Tuning S2Sharp parameters for', dataset)\n",
    "        S2sharppars = opt_method(method, S2sharpparameters, max_evals, dataset=dataset, metric='sre', eval_bands=eval_bands, verbose=True, savefile=result_dir + '/' + dataset + '/' + 'S2sharp')\n",
    "        best_pars[dataset]['S2Sharp'] = S2sharppars\n",
    "    except:\n",
    "        print('Parameter tuning for S2Sharp failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once code has been placed in appropriate folders change the following cells from raw to code in order to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best parameters for ATPRK"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eng.addpath('./ATPRK')\n",
    "ATPRKwrap = eng.ATPRKwrap\n",
    "method = ATPRKwrap\n",
    "ATPRKparameters = {'Sill_min': ['double', 1.0, ('uniform_int', 1, 3)], 'Range_min': ['double', 0.5, ('lognormal', 0, 0.5)], 'L_sill': ['double', 20, ('uniform_int', 10, 30)], 'L_range': ['double', 20, ('uniform_int', 10, 30)], 'rate': ['double', 0.1, ('lognormal', 0, 0.5)], 'H': ['double', 20, ('uniform_int', 10, 30)]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in datasets:\n",
    "    try:\n",
    "        print('Tuning ATPRK parameters for', dataset)\n",
    "        ATPRKpars = opt_method(method, ATPRKparameters, max_evals, dataset=dataset, metric=metric, eval_bands=eval_bands, verbose=True, savefile=result_dir + '/' + dataset + '/' + 'ATPRK')\n",
    "        best_pars[dataset]['ATPRK'] = ATPRKpars\n",
    "    except:\n",
    "        print('Parameter tuning failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best parameters for SSSS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eng.addpath('./SSSS')\n",
    "SSSSwrap = eng.SSSSwrap\n",
    "method = SSSSwrap\n",
    "SSSSparameters = {'lam': ['double', 0.1, ('lognormal', np.exp(0.1), 0.5)], \n",
    "              'mu': ['double', 0.1, ('lognormal', np.exp(0.1), 0.5)],\n",
    "              'ksize': ['double', 13, ('constant')]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in data_list:\n",
    "    try:\n",
    "        print('Tuning SSSS parameters for', dataset)\n",
    "        SSSSpars = opt_method(method, SSSSparameters, max_evals, dataset=dataset, metric=metric, eval_bands=eval_bands, verbose=True, savefile=result_dir + '/' + dataset + '/' + 'SSSS')\n",
    "        best_pars[dataset]['SSSS'] = SSSSpars\n",
    "    except:\n",
    "        print('Parameter tuning failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best parameters for SupReME"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eng.addpath('./SupReME')\n",
    "SupReMEwrap = eng.SupReMEwrap\n",
    "method = SupReMEwrap\n",
    "SupReMEparameters = {'p': ['int', 7, ('constant')],\n",
    "              'lam': ['double', 0.005, ('lognormal', np.exp(0.005), 0.5)]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in data_list:\n",
    "    try:\n",
    "        print('Tuning SupReME parameters for', dataset)\n",
    "        SupReMEpars = opt_method(method, SupReMEparameters, max_evals, dataset=dataset, metric=metric, eval_bands=eval_bands, verbose=True, savefile=result_dir + '/' + dataset + '/' + 'SupReME')\n",
    "        best_pars[dataset]['SupReME'] = SupReMEpars\n",
    "    except:\n",
    "        print('Parameter tuning failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best parameters for MuSA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eng.addpath('./MusaCode')\n",
    "MuSAwrap = eng.MuSAwrap\n",
    "method = MuSAwrap\n",
    "MuSAparameters = {'lam': ['double', 0.005, ('lognormal', np.exp(0.005), 0.5)], \n",
    "              'mu': ['double', 0.6, ('lognormal', np.exp(0.6), 0.5)],\n",
    "              'niters': ['int', 50, ('constant')]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in data_list:\n",
    "    try:\n",
    "        print('Tuning MuSA parameters for', dataset)\n",
    "        MuSApars = opt_method(method, MuSAparameters, max_evals, dataset=dataset, metric=metric, eval_bands=eval_bands, verbose=True, savefile=result_dir + '/' + dataset + '/' + 'MuSA')\n",
    "        best_pars[dataset]['MuSA'] = MuSApars\n",
    "    except:\n",
    "        print('Parameter tuning failed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the best parameters, copy results into `boars.py` to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print('best_pars =', json.dumps(best_pars, sort_keys=True, indent=4).replace(\"true\",\"True\").replace(\"false\",\"False\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run methods with best parameters and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_run=False\n",
    "verbose=True\n",
    "limsub = 6\n",
    "eval_bands=None\n",
    "eval_dfs = {}\n",
    "Yims = {}\n",
    "Xm_ims = {}\n",
    "Xhats = {}\n",
    "\n",
    "band_scales = np.array([6, 1, 1, 1, 2, 2, 2, 1, 2, 6, 2, 2])\n",
    "band_names = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\n",
    "band_idxs = {'B1':0, 'B2':1, 'B3':2, 'B4':3, 'B5':4, 'B6':5, 'B7':6, 'B8':7, 'B8A':8, 'B9':9, 'B11':10, 'B12':11}\n",
    "\n",
    "for dataset in data_list:\n",
    "    #Load data\n",
    "    (Yim, Xm_im, eval_bands) = get_data(dataset, datadir='./data/')\n",
    "    (Yim, mtf) = get_data(dataset, datadir='./data/', get_mtf=True)[:2]\n",
    "    # Format for matlab methods\n",
    "    mYim = [matlab.double(b.tolist()) for b in Yim]\n",
    "    mXm_im =[]\n",
    "    for b in range(Xm_im.shape[-1]):\n",
    "        mXm_im.append(matlab.double(Xm_im[:,:,b].tolist()))\n",
    "    mXm_im = matlab.double(mXm_im)\n",
    "    mXm_im = eng.permute(mXm_im, matlab.int16([2,3,1]))\n",
    "    Yims[dataset] = Yim\n",
    "    Xm_ims[dataset] = Xm_im\n",
    "    Xhats[dataset] = {}\n",
    "    for meth_name in meth_list:\n",
    "        try:\n",
    "            if verbose: print('Processing', dataset, 'with', meth_name, '!')\n",
    "            method = get_method(meth_name, matlab_handle=eng)\n",
    "            pars = best_pars.get(dataset, best_pars['default']).get(meth_name, {})\n",
    "            if meth_name is 'SSC' or meth_name is 'DSen2':\n",
    "                Xhat = method(Yim, **pars)\n",
    "            else:\n",
    "                Xhat = np.array(method(mYim, *pardict_to_matlist(pars)))\n",
    "            Xhats[dataset][meth_name] = Xhat\n",
    "            if verbose: print(meth_name, 'done!')\n",
    "        except:\n",
    "            print(meth_name, 'failed!')\n",
    "    np.savez_compressed(result_dir + '/' + dataset + '/srdata.npz', **Xhats[dataset])\n",
    "    if eval_bands is not None:\n",
    "        res_list = sreval(Xm_im, Xhats[dataset].values(), limsub=limsub, bands=eval_bands)\n",
    "        evals_df = dataframe_from_res_list(res_list, Xhats[dataset].keys(), band_idxs, multi_run=multi_run)\n",
    "        evals_df = evals_df.drop(['B2','B3','B4','B8'], level=1)\n",
    "        if 2 not in eval_bands:\n",
    "            evals_df = evals_df.drop(['B5','B6','B7','B8A', 'B11', 'B12','20m','All'], level=1)\n",
    "        if 6 not in eval_bands:\n",
    "            evals_df = evals_df.drop(['B1','B9','60m','All'], level=1)\n",
    "        evals_df.to_csv(result_dir + '/' + dataset + '/tuned_comparison.csv',sep='\\t',decimal='.')\n",
    "        evals_df.to_hdf(result_dir + '/' + dataset + '/tuned_comparison_dataframe.h5', key=dataset)\n",
    "        eval_dfs[dataset] = evals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip=10000\n",
    "cmap='gray_r'\n",
    "for dataset in data_list:\n",
    "    imdir = result_dir + '/' + dataset + '/images/'\n",
    "    for band in ['B1', 'B5', 'B6', 'B7', 'B8A', 'B9', 'B11', 'B12']:\n",
    "        os.makedirs(imdir + band, exist_ok = True)\n",
    "        \n",
    "        print('Input', band)\n",
    "        cbar_fig, cbar_ax = plt.subplots()\n",
    "        fig, ax = plt.subplots()\n",
    "        cbar_fig.set_figwidth(fig.get_figwidth()/30)\n",
    "        sns_plot = sns.heatmap(Yims[dataset][band_idxs[band]][:,:],\n",
    "                    xticklabels=False, yticklabels=False, vmin=0, vmax=clip,\n",
    "                    square=True, cmap=cmap, ax=ax, cbar_ax=cbar_ax)\n",
    "        plt.grid(False)\n",
    "        fig.savefig(imdir + band + '/input_f.png', bbox_inches='tight')\n",
    "        cbar_fig.savefig(imdir + band + '/input_f_cbar.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        plt.close(cbar_fig)\n",
    "\n",
    "        print('Ground truth')\n",
    "        if np.isnan(Xm_ims[dataset][:,:,band_idxs[band]]).any():\n",
    "            print('NaN')\n",
    "        else:\n",
    "            cbar_fig, cbar_ax = plt.subplots()\n",
    "            fig, ax = plt.subplots()\n",
    "            cbar_fig.set_figwidth(fig.get_figwidth()/30)\n",
    "            sns_plot = sns.heatmap(Xm_ims[dataset][:,:,band_idxs[band]],\n",
    "                        xticklabels=False, yticklabels=False, vmin=0, vmax=clip,\n",
    "                        square=True, cmap=cmap, ax=ax, cbar_ax=cbar_ax)\n",
    "            plt.grid(False)\n",
    "            fig.savefig(imdir + band + '/gt_f.png', bbox_inches='tight')\n",
    "            cbar_fig.savefig(imdir + band + '/gt_f_cbar.png', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "            plt.close(cbar_fig)\n",
    "\n",
    "        print('Input zoom')\n",
    "        cbar_fig, cbar_ax = plt.subplots()\n",
    "        fig, ax = plt.subplots()\n",
    "        cbar_fig.set_figwidth(fig.get_figwidth()/30)\n",
    "        z = 16 if band in ['B1', 'B9'] else 48\n",
    "        sns_plot = sns.heatmap(Yims[dataset][band_idxs[band]][:z,:z],\n",
    "                    xticklabels=False, yticklabels=False, vmin=0, vmax=clip,\n",
    "                    square=True, cmap=cmap, ax=ax, cbar_ax=cbar_ax)\n",
    "        plt.grid(False)\n",
    "        fig.savefig(imdir + band + '/input_z.png', bbox_inches='tight')\n",
    "        cbar_fig.savefig(imdir + band + '/input_z_cbar.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        plt.close(cbar_fig)\n",
    "\n",
    "        print('Ground truth zoom')\n",
    "        if np.isnan(Xm_ims[dataset][:96,:96,band_idxs[band]]).any():\n",
    "            print('NaN')\n",
    "        else:\n",
    "            cbar_fig, cbar_ax = plt.subplots()\n",
    "            fig, ax = plt.subplots()\n",
    "            cbar_fig.set_figwidth(fig.get_figwidth()/30)\n",
    "            sns_plot = sns.heatmap(Xm_ims[dataset][:96,:96,band_idxs[band]],\n",
    "                        xticklabels=False, yticklabels=False, vmin=0, vmax=clip,\n",
    "                        square=True, cmap=cmap, ax=ax, cbar_ax=cbar_ax)\n",
    "            plt.grid(False)\n",
    "            fig.savefig(imdir + band + '/gt_z.png', bbox_inches='tight')\n",
    "            cbar_fig.savefig(imdir + band + '/gt_z_cbar.png', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "            plt.close(cbar_fig)\n",
    "        for method, Xhat_im in Xhats[dataset].items():\n",
    "            print(band, method)\n",
    "            if np.isnan(Xhat_im[:96,:96,band_idxs[band]]).any():\n",
    "                print('NaN')\n",
    "            else:\n",
    "                cbar_fig, cbar_ax = plt.subplots()\n",
    "                fig, ax = plt.subplots()\n",
    "                cbar_fig.set_figwidth(fig.get_figwidth()/30)\n",
    "                sns_plot = sns.heatmap(np.maximum(0,Xhat_im[:96,:96,band_idxs[band]]),\n",
    "                            xticklabels=False, yticklabels=False, vmin=0, vmax=clip,\n",
    "                            square=True, cmap=cmap, cbar_ax=cbar_ax, ax=ax)\n",
    "                plt.grid(False)\n",
    "                fig.savefig(imdir + band + '/' + method + '_z.png', bbox_inches='tight')\n",
    "                cbar_fig.savefig(imdir + band + '/' + method + '_z_cbar.png', bbox_inches='tight')\n",
    "                plt.show()\n",
    "                plt.close(fig)\n",
    "                plt.close(cbar_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min(data):\n",
    "    attr = 'color: red'\n",
    "\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_min = data == data.min()\n",
    "        return [attr if v else '' for v in is_min]\n",
    "    else: \n",
    "        is_min = data.groupby(level=0).transform('min') == data\n",
    "        return pd.DataFrame(np.where(is_min, attr, ''),\n",
    "                            index=data.index, columns=data.columns)\n",
    "def highlight_max(data):\n",
    "    attr = 'color: red'\n",
    "\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else: \n",
    "        is_max = data.groupby(level=0).transform('max') == data\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)\n",
    "    \n",
    "def bold_formatter(x, value, num_decimals=4):\n",
    "    \"\"\"Format a number in bold when (almost) identical to a given value.\n",
    "    \n",
    "    Args:\n",
    "        x: Input number.\n",
    "        \n",
    "        value: Value to compare x with.\n",
    "        \n",
    "        num_decimals: Number of decimals to use for output format.\n",
    "\n",
    "    Returns:\n",
    "        String converted output.\n",
    "\n",
    "    \"\"\"\n",
    "    # Consider values equal, when rounded results are equal\n",
    "    # otherwise, it may look surprising in the table where they seem identical\n",
    "    if round(x, num_decimals) == round(value, num_decimals):\n",
    "        return f\"\\\\bfseries  {x:.{num_decimals}f}\"\n",
    "    else:\n",
    "        if np.isnan(x): return '{--}'\n",
    "        else: return f\"{x:.{num_decimals}f}\"\n",
    "\n",
    "\n",
    "def make_bfseries(x):\n",
    "        return f\"\\\\bfseries {x:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, eval_df in eval_dfs.items():\n",
    "    print(key)\n",
    "    styled_df = eval_df.T.loc[slice(None), (['RMSE','SAM','ERGAS'], slice(None))].T.style.apply(highlight_min, axis=1)\n",
    "    display(styled_df)\n",
    "    styled_df = eval_df.T.loc[slice(None), (['SRE'], slice(None))].T.style.apply(highlight_max, axis=1)\n",
    "    display(styled_df)\n",
    "    styled_df = eval_df.T.loc[slice(None), (['SSIM'], slice(None))].T.style.apply(highlight_max, axis=1)\n",
    "    display(styled_df)\n",
    "    styled_df = eval_df.T.loc[slice(None), (['UIQI'], slice(None))].T.style.apply(highlight_max, axis=1)\n",
    "    display(styled_df)\n",
    "    for metric in [['UIQI'],['SSIM'],['SRE'],['RMSE','SAM','ERGAS']]:\n",
    "        styled_df = eval_df.T.loc[slice(None), (metric, slice(None))]\n",
    "\n",
    "        styled_keys = styled_df.keys()\n",
    "        min_columns_2f = [k for k in styled_keys if 'ERGAS' in k or 'RMSE' in k or 'SAM' in k]\n",
    "        max_columns_2f = [k for k in styled_keys if 'UIQI' in k or 'SSIM' in k or 'SRE' in k]\n",
    "\n",
    "        fmts_max_2f = {column: partial(bold_formatter, value=styled_df[column].max(), num_decimals=2) for column in max_columns_2f}\n",
    "        fmts_min_2f = {column: partial(bold_formatter, value=styled_df[column].min(), num_decimals=2) for column in min_columns_2f}\n",
    "\n",
    "        fmts = {**fmts_max_2f, **fmts_min_2f}\n",
    "        for k in styled_df.columns.values:\n",
    "            if k in fmts:\n",
    "                styled_df[k] = styled_df[k].apply(fmts[k])\n",
    "        os.makedirs(os.path.dirname(result_dir + \"/\" + key + \"/\"), exist_ok=True)\n",
    "        with open(result_dir + \"/\" + key + \"/\" + metric[0] + \".tex\", \"w\") as fh:\n",
    "            styled_df.T.to_latex(buf=fh,\n",
    "                               na_rep = '--',\n",
    "                               multicolumn=False,\n",
    "                               index_names=True,\n",
    "                               escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
